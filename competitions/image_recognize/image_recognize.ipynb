{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 识别谷歌街景图片中的字母\n",
    "\n",
    "[street-view-getting-started-with-julia](https://www.kaggle.com/c/street-view-getting-started-with-julia) 让我们从谷歌街景的图片中鉴定字母，这个题目是让我们学习和使用Julia，Julia有python和R的易用性，有C语言的速度，无奈对Julia不是很熟悉，所以还是想用python来试试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们希望所有的图片最后存储在一个numpy的矩阵当中，每一行为图片的像素值。为了得到统一的表达呢，我们将RGB三个通道的值做平均得到的灰度图像作为每个图片的表示:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# typeData 为\"train\"或者\"test\"\n",
    "# labelsInfo 包含每一个图片的ID\n",
    "# 图片存储在trainResized和testResized文件夹内\n",
    "def read_data(typeData, labelsInfo, imageSize):\n",
    "    labelsIndex = labelsInfo[\"ID\"]\n",
    "    x = np.zeros((np.size(labelsIndex), imageSize))\n",
    "    for idx, idImage in enumerate(labelsIndex):\n",
    "        # 得到图片文件名并读取\n",
    "        nameFile = typeData + \"Resized/\" + str(idImage) + \".Bmp\"\n",
    "        img = cv2.imread(nameFile)\n",
    "        # 转化为灰度图\n",
    "        temp = np.mean(img, 2)\n",
    "        # 将图片转化为行向量\n",
    "        x[idx, :] = np.reshape(temp, (1, imageSize))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imageSize = 400\n",
    "trainlabels = pd.read_csv(\"trainLabels.csv\")\n",
    "testlabels = pd.read_csv(\"sampleSubmission.csv\")\n",
    "# 得到训练集的特征\n",
    "xTrain = read_data('train', trainlabels, imageSize)\n",
    "# 得到测试集的特征\n",
    "xTest = read_data(\"test\", testlabels, imageSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预览数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID Class\n",
      "0   1     n\n",
      "1   2     8\n",
      "     ID Class\n",
      "0  6284     A\n",
      "1  6285     A\n"
     ]
    }
   ],
   "source": [
    "print trainlabels.head(2)\n",
    "print testlabels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yTrain = trainlabels[\"Class\"]\n",
    "yTrain = [ord(x) for x in yTrain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "### 随机森林\n",
    "\n",
    "使用随机森林进行训练，树的个数和深度需要多次调解寻求最佳值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 121 µs, sys: 367 µs, total: 488 µs\n",
      "Wall time: 494 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=50, max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%time rfc = RandomForestClassifier(n_estimators = 500, max_features = 50, max_depth=None)\n",
    "rfc.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预测\n",
    "将训练后的模型应用到测试集上，并保存结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predTest = rfc.predict(xTest)\n",
    "predResult = [chr(x) for x in predTest]\n",
    "testlabels[\"Class\"] = predResult\n",
    "testlabels.to_csv(\"rf_500_50_result.csv\",index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 结果\n",
    "使用50颗树进行训练，提交kaggle之后准确率约为0.40  \n",
    "改用300颗树进行训练，提交kaggle之后准确率为0.46695  \n",
    "改用500颗树进行训练，深度为10，提价kaggle后准确率为0.40，估计出现了过拟合  \n",
    "改用500颗树进行训练，不设置深度，提价kaggle后准确率为0.47480  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB as GNB\n",
    "model_GNB = GNB()\n",
    "model_GNB.fit(xTrain, yTrain)\n",
    "\n",
    "predTest = model_GNB.predict(xTest)\n",
    "predResult = [chr(x) for x in predTest]\n",
    "testlabels[\"Class\"] = predResult\n",
    "testlabels.to_csv(\"gnb_result.csv\",index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "贝叶斯的训练非常的快，把结果提交kaggle后，得到0.02389的准确率，明显低于随机森林"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 91 µs, sys: 738 µs, total: 829 µs\n",
      "Wall time: 2.93 ms\n",
      "CPU times: user 40min 16s, sys: 52.3 s, total: 41min 9s\n",
      "Wall time: 2h 55min 22s\n",
      "CPU times: user 1.75 s, sys: 44.5 ms, total: 1.8 s\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "%time GBDT = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, \\\n",
    "                        min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, init=None, \\\n",
    "                        random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "\n",
    "%time GBDT.fit(xTrain, yTrain)\n",
    "\n",
    "%time predTest = GBDT.predict(xTest)\n",
    "predResult = [chr(x) for x in predTest]\n",
    "testlabels[\"Class\"] = predResult\n",
    "testlabels.to_csv(\"gbdt_result.csv\",index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用GBDT仅得到了0.31937的准确率，可能是我的默认参数没有调节好，关键是GBDT的训练时间太长，调试成本也比较高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage.io import imread\n",
    "from lasagne import layers\n",
    "from lasagne.nonlinearities import softmax\n",
    "from nolearn.lasagne import NeuralNet, BatchIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define functions\n",
    "def read_datax(typeData, labelsInfo, imageSize, path):\n",
    "    x = np.zeros((labelsInfo.shape[0], imageSize))\n",
    "    \n",
    "    for (index, idImage) in enumerate(labelsInfo['ID']):\n",
    "        # use specially created 32 x 32 images\n",
    "        nameFile = '{0}/{1}Resized32/{2}.Bmp'.format(path, \n",
    "                    typeData, idImage)\n",
    "        img = imread(nameFile, as_grey = True)\n",
    "        \n",
    "        x[index, :] = np.reshape(img, (1, imageSize))\n",
    "        \n",
    "    return x\n",
    "\n",
    "def fit_model(reshaped_train_x, y, image_width, \n",
    "                    image_height, reshaped_test_x):\n",
    "    net = NeuralNet(\n",
    "        layers = [\n",
    "            ('input', layers.InputLayer),\n",
    "            ('conv1', layers.Conv2DLayer),\n",
    "            ('pool1', layers.MaxPool2DLayer),\n",
    "            ('dropout1', layers.DropoutLayer),\n",
    "            ('conv2', layers.Conv2DLayer),\n",
    "            ('pool2', layers.MaxPool2DLayer),\n",
    "            ('dropout2', layers.DropoutLayer),\n",
    "            ('conv3', layers.Conv2DLayer),\n",
    "            ('hidden4', layers.DenseLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "        ],\n",
    "        input_shape = (None, 1, 32, 32),\n",
    "        conv1_num_filters=32, conv1_filter_size=(5, 5), \n",
    "        pool1_pool_size=(2, 2),\n",
    "        dropout1_p=0.2,\n",
    "        conv2_num_filters=64, conv2_filter_size=(5, 5), \n",
    "        pool2_pool_size=(2, 2),\n",
    "        dropout2_p=0.2,\n",
    "        conv3_num_filters = 128, conv3_filter_size = (5, 5),\n",
    "        hidden4_num_units=500,\n",
    "        output_num_units = 62, output_nonlinearity = softmax,\n",
    "        \n",
    "        update_learning_rate = 0.01,\n",
    "        update_momentum = 0.9,\n",
    "        \n",
    "        batch_iterator_train = BatchIterator(batch_size = 100),\n",
    "        batch_iterator_test = BatchIterator(batch_size = 100),\n",
    "        \n",
    "        use_label_encoder = True,\n",
    "        regression = False,\n",
    "        max_epochs = 100,\n",
    "        verbose = 1,\n",
    "    )\n",
    "    \n",
    "    net.fit(reshaped_train_x, y)\n",
    "    prediction = net.predict(reshaped_test_x)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 预处理数据，首先将图片保存为32*32的小图片\n",
    "imageSize = 1024 # 32 x 32\n",
    "image_width = image_height = int(imageSize ** 0.5)\n",
    "\n",
    "labelsInfoTrain = pd.read_csv\\\n",
    "            ('trainLabels.csv'.format(path))\n",
    "labelsInfoTest = pd.read_csv\\\n",
    "            ('sampleSubmission.csv'.format(path))\n",
    "\n",
    "# Load dataset\n",
    "nnxTrain = read_datax('train', labelsInfoTrain, imageSize, '.')\n",
    "nnxTest = read_datax('test', labelsInfoTest, imageSize, '.')\n",
    "\n",
    "nnyTrain = map(ord, labelsInfoTrain['Class'])\n",
    "nnyTrain = np.array(yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 归一化数据\n",
    "nnxTrain /= nnxTrain.std(axis = None)\n",
    "nnxTrain -= nnxTrain.mean()\n",
    "\n",
    "nnxTest /= nnxTest.std(axis = None)\n",
    "nnxTest -= nnxTest.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape data\n",
    "train_x_reshaped = nnxTrain.reshape(nnxTrain.shape[0], 1, \n",
    "                  image_height, image_width).astype('float32')\n",
    "test_x_reshaped = nnxTest.reshape(nnxTest.shape[0], 1, \n",
    "                  image_height, image_width).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 352586 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  --------  --------\n",
      "  0  input     1x32x32\n",
      "  1  conv1     32x28x28\n",
      "  2  pool1     32x14x14\n",
      "  3  dropout1  32x14x14\n",
      "  4  conv2     64x10x10\n",
      "  5  pool2     64x5x5\n",
      "  6  dropout2  64x5x5\n",
      "  7  conv3     128x1x1\n",
      "  8  hidden4   500\n",
      "  9  output    62\n",
      "\n",
      "  epoch    trn loss    val loss    trn/val    valid acc  dur\n",
      "-------  ----------  ----------  ---------  -----------  ------\n",
      "      1     \u001b[36m4.08201\u001b[0m     \u001b[32m4.01012\u001b[0m    1.01793      0.07254  16.55s\n",
      "      2     \u001b[36m3.87688\u001b[0m     \u001b[32m3.84326\u001b[0m    1.00875      0.04836  17.72s\n",
      "      3     \u001b[36m3.82788\u001b[0m     \u001b[32m3.79976\u001b[0m    1.00740      0.04914  16.58s\n",
      "      4     \u001b[36m3.78741\u001b[0m     \u001b[32m3.78872\u001b[0m    0.99965      0.07254  16.14s\n",
      "      5     \u001b[36m3.78030\u001b[0m     \u001b[32m3.78600\u001b[0m    0.99850      0.07254  16.37s\n",
      "      6     \u001b[36m3.77679\u001b[0m     \u001b[32m3.78520\u001b[0m    0.99778      0.07254  16.56s\n",
      "      7     \u001b[36m3.77487\u001b[0m     3.78537    0.99723      0.07254  16.30s\n",
      "      8     \u001b[36m3.77411\u001b[0m     \u001b[32m3.78468\u001b[0m    0.99721      0.07254  16.51s\n",
      "      9     \u001b[36m3.77257\u001b[0m     3.78518    0.99667      0.07254  15.92s\n",
      "     10     \u001b[36m3.77202\u001b[0m     \u001b[32m3.78459\u001b[0m    0.99668      0.07254  16.55s\n",
      "     11     \u001b[36m3.76948\u001b[0m     \u001b[32m3.78458\u001b[0m    0.99601      0.07254  16.25s\n",
      "     12     \u001b[36m3.76882\u001b[0m     \u001b[32m3.78414\u001b[0m    0.99595      0.07254  16.31s\n",
      "     13     \u001b[36m3.76717\u001b[0m     \u001b[32m3.78411\u001b[0m    0.99552      0.07254  15.70s\n",
      "     14     \u001b[36m3.76606\u001b[0m     3.78469    0.99508      0.07254  16.04s\n",
      "     15     \u001b[36m3.76419\u001b[0m     3.78671    0.99405      0.07176  15.70s\n",
      "     16     \u001b[36m3.76277\u001b[0m     \u001b[32m3.78392\u001b[0m    0.99441      0.07176  16.05s\n",
      "     17     \u001b[36m3.76014\u001b[0m     3.78821    0.99259      0.07176  15.71s\n",
      "     18     3.78179     3.78606    0.99887      0.07254  16.11s\n",
      "     19     3.76928     \u001b[32m3.78321\u001b[0m    0.99632      0.07254  15.75s\n",
      "     20     3.76688     3.78358    0.99559      0.07254  16.05s\n",
      "     21     3.76434     \u001b[32m3.78255\u001b[0m    0.99519      0.07254  17.36s\n",
      "     22     3.76186     \u001b[32m3.78174\u001b[0m    0.99474      0.07254  18.12s\n",
      "     23     \u001b[36m3.75829\u001b[0m     3.78184    0.99377      0.07878  17.90s\n",
      "     24     \u001b[36m3.75370\u001b[0m     3.78545    0.99161      0.07488  18.19s\n",
      "     25     \u001b[36m3.74749\u001b[0m     \u001b[32m3.77908\u001b[0m    0.99164      0.07098  17.81s\n",
      "     26     \u001b[36m3.73650\u001b[0m     \u001b[32m3.77806\u001b[0m    0.98900      0.07020  18.08s\n",
      "     27     \u001b[36m3.71592\u001b[0m     \u001b[32m3.77626\u001b[0m    0.98402      0.06474  18.03s\n",
      "     28     \u001b[36m3.67805\u001b[0m     \u001b[32m3.74531\u001b[0m    0.98204      0.07176  18.04s\n",
      "     29     \u001b[36m3.59550\u001b[0m     3.79802    0.94668      0.07566  18.12s\n",
      "     30     \u001b[36m3.44086\u001b[0m     \u001b[32m3.35483\u001b[0m    1.02564      0.19111  18.06s\n",
      "     31     \u001b[36m3.14160\u001b[0m     \u001b[32m3.00021\u001b[0m    1.04713      0.29251  17.41s\n",
      "     32     \u001b[36m2.73389\u001b[0m     \u001b[32m2.89130\u001b[0m    0.94556      0.31903  16.19s\n",
      "     33     \u001b[36m2.61587\u001b[0m     \u001b[32m2.53098\u001b[0m    1.03354      0.38144  15.73s\n",
      "     34     \u001b[36m2.25316\u001b[0m     \u001b[32m2.26086\u001b[0m    0.99660      0.43994  16.14s\n",
      "     35     \u001b[36m1.95499\u001b[0m     \u001b[32m2.03661\u001b[0m    0.95993      0.48206  15.76s\n",
      "     36     \u001b[36m1.75483\u001b[0m     \u001b[32m1.94987\u001b[0m    0.89997      0.49610  16.01s\n",
      "     37     \u001b[36m1.60276\u001b[0m     \u001b[32m1.78637\u001b[0m    0.89722      0.52106  15.60s\n",
      "     38     \u001b[36m1.47862\u001b[0m     \u001b[32m1.73524\u001b[0m    0.85211      0.54524  15.98s\n",
      "     39     \u001b[36m1.35049\u001b[0m     \u001b[32m1.65705\u001b[0m    0.81500      0.55694  15.62s\n",
      "     40     \u001b[36m1.27458\u001b[0m     \u001b[32m1.65253\u001b[0m    0.77129      0.57254  16.01s\n",
      "     41     \u001b[36m1.18548\u001b[0m     \u001b[32m1.60550\u001b[0m    0.73839      0.58112  15.61s\n",
      "     42     \u001b[36m1.11862\u001b[0m     1.62259    0.68940      0.58268  16.51s\n",
      "     43     \u001b[36m1.05698\u001b[0m     1.68044    0.62899      0.58112  16.24s\n",
      "     44     \u001b[36m1.01350\u001b[0m     1.64642    0.61558      0.59126  16.50s\n",
      "     45     \u001b[36m0.93587\u001b[0m     1.62059    0.57749      0.59906  15.81s\n",
      "     46     \u001b[36m0.87893\u001b[0m     1.65983    0.52953      0.59984  16.54s\n",
      "     47     \u001b[36m0.83695\u001b[0m     1.66309    0.50325      0.60452  16.42s\n",
      "     48     1.72887     2.92194    0.59169      0.54446  16.31s\n",
      "     49     3.85830     3.39520    1.13640      0.21373  15.84s\n",
      "     50     2.26598     1.97743    1.14592      0.46724  18.41s\n",
      "     51     2.11105     1.89927    1.11150      0.49298  18.02s\n",
      "     52     1.66393     1.75705    0.94700      0.51794  17.99s\n",
      "     53     1.48332     1.65795    0.89467      0.54212  17.94s\n",
      "     54     1.38197     \u001b[32m1.60296\u001b[0m    0.86214      0.55928  17.73s\n",
      "     55     1.28419     \u001b[32m1.56050\u001b[0m    0.82293      0.56318  17.94s\n",
      "     56     1.21078     \u001b[32m1.54983\u001b[0m    0.78123      0.57176  17.70s\n",
      "     57     1.13885     1.55330    0.73318      0.55616  17.93s\n",
      "     58     1.10488     \u001b[32m1.53462\u001b[0m    0.71997      0.57956  17.71s\n",
      "     59     1.03479     1.54234    0.67092      0.58502  17.70s\n",
      "     60     0.98439     \u001b[32m1.52492\u001b[0m    0.64554      0.59984  17.95s\n",
      "     61     0.93277     \u001b[32m1.49128\u001b[0m    0.62548      0.59204  17.67s\n",
      "     62     1.03055     1.58280    0.65109      0.57878  18.01s\n",
      "     63     0.89008     1.54904    0.57460      0.59750  17.69s\n",
      "     64     0.83698     1.59463    0.52487      0.58346  17.92s\n",
      "     65     \u001b[36m0.79801\u001b[0m     1.59534    0.50021      0.60452  17.80s\n",
      "     66     \u001b[36m0.77752\u001b[0m     1.56702    0.49618      0.60842  17.91s\n",
      "     67     \u001b[36m0.73901\u001b[0m     1.61821    0.45668      0.59594  17.81s\n",
      "     68     \u001b[36m0.71108\u001b[0m     1.56703    0.45377      0.61154  17.98s\n",
      "     69     \u001b[36m0.67279\u001b[0m     1.61497    0.41659      0.61154  17.81s\n",
      "     70     \u001b[36m0.64651\u001b[0m     1.66452    0.38841      0.60530  17.97s\n",
      "     71     \u001b[36m0.61597\u001b[0m     1.65828    0.37145      0.62012  17.84s\n",
      "     72     \u001b[36m0.59188\u001b[0m     1.69796    0.34858      0.60296  17.92s\n",
      "     73     \u001b[36m0.57862\u001b[0m     1.72392    0.33564      0.60686  17.73s\n",
      "     74     \u001b[36m0.56451\u001b[0m     1.75449    0.32175      0.60062  17.56s\n",
      "     75     \u001b[36m0.53835\u001b[0m     1.74351    0.30877      0.62090  17.77s\n",
      "     76     \u001b[36m0.53288\u001b[0m     1.80642    0.29499      0.60842  18.08s\n",
      "     77     \u001b[36m0.49975\u001b[0m     1.76941    0.28244      0.61700  17.76s\n",
      "     78     \u001b[36m0.48489\u001b[0m     1.75930    0.27561      0.60998  17.92s\n",
      "     79     \u001b[36m0.45688\u001b[0m     1.81943    0.25111      0.61622  17.78s\n",
      "     80     0.46801     1.80187    0.25974      0.62480  17.96s\n",
      "     81     \u001b[36m0.45527\u001b[0m     1.88136    0.24199      0.61310  17.84s\n",
      "     82     \u001b[36m0.43178\u001b[0m     1.93961    0.22261      0.61622  18.56s\n",
      "     83     \u001b[36m0.41726\u001b[0m     1.90341    0.21922      0.61856  16.52s\n",
      "     84     \u001b[36m0.38590\u001b[0m     1.91029    0.20201      0.61778  15.59s\n",
      "     85     \u001b[36m0.38510\u001b[0m     1.93524    0.19900      0.61778  16.00s\n",
      "     86     \u001b[36m0.37565\u001b[0m     1.92514    0.19513      0.61466  15.56s\n",
      "     87     \u001b[36m0.36222\u001b[0m     1.99870    0.18123      0.61544  15.88s\n",
      "     88     0.38495     2.08839    0.18433      0.61466  15.55s\n",
      "     89     \u001b[36m0.34101\u001b[0m     1.94872    0.17499      0.62559  15.97s\n",
      "     90     \u001b[36m0.33575\u001b[0m     2.01506    0.16662      0.61856  15.63s\n",
      "     91     \u001b[36m0.32353\u001b[0m     2.05956    0.15709      0.62090  16.03s\n",
      "     92     \u001b[36m0.30422\u001b[0m     2.12548    0.14313      0.64041  15.66s\n",
      "     93     \u001b[36m0.29631\u001b[0m     2.10645    0.14067      0.63495  16.02s\n",
      "     94     0.32050     2.11861    0.15128      0.62168  15.73s\n",
      "     95     0.30140     2.14516    0.14050      0.62871  15.99s\n",
      "     96     \u001b[36m0.28195\u001b[0m     2.09292    0.13472      0.63339  15.67s\n",
      "     97     0.30323     2.20744    0.13737      0.62246  16.07s\n",
      "     98     \u001b[36m0.27107\u001b[0m     2.15645    0.12570      0.63729  16.32s\n",
      "     99     0.27947     2.22565    0.12557      0.62637  16.51s\n",
      "    100     \u001b[36m0.26500\u001b[0m     2.22825    0.11893      0.64431  16.52s\n"
     ]
    }
   ],
   "source": [
    "# 进行训练和测试\n",
    "predict = fit_model(train_x_reshaped, nnyTrain, image_width, image_height, test_x_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 保存结果\n",
    "yTest = map(chr, predict)\n",
    "labelsInfoTest['Class'] = yTest\n",
    "labelsInfoTest.to_csv('nnresult.csv'.format(path), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提交kaggle之后的准确率：0.64562"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
