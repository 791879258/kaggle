{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[facial-keypoints-detection](https://www.kaggle.com/c/facial-keypoints-detection), 这是一个人脸识别任务，任务是识别人脸图片中的眼睛、鼻子、嘴的位置。训练集包含以下15个位置的坐标，行末是图片的像素值，共96*96个像素值。测试集只包含图片的像素值。\n",
    "```\n",
    "left_eye_center, right_eye_center, left_eye_inner_corner, left_eye_outer_corner, right_eye_inner_corner, right_eye_outer_corner, left_eyebrow_inner_end, left_eyebrow_outer_end, right_eyebrow_inner_end, right_eyebrow_outer_end, nose_tip, mouth_left_corner, mouth_right_corner, mouth_center_top_lip, mouth_center_bottom_lip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lasagne import layers\n",
    "from nolearn.lasagne import BatchIterator\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "import theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据载入与预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = 'training.csv'\n",
    "test_file = 'test.csv'\n",
    "\n",
    "def load(test=False, cols=None):\n",
    "    \"\"\"\n",
    "    载入数据，通过参数控制载入训练集还是测试集，并筛选特征列\n",
    "    \"\"\"\n",
    "    fname = test_file if test else train_file\n",
    "    df = pd.read_csv(os.path.expanduser(fname))\n",
    "\n",
    "    # 将图像数据转换为数组\n",
    "    df['Image'] = df['Image'].apply(lambda x: np.fromstring(x, sep=' '))\n",
    "\n",
    "    # 筛选指定的数据列\n",
    "    if cols:  \n",
    "        df = df[list(cols) + ['Image']]\n",
    "\n",
    "    print(df.count())  # 每列的简单统计\n",
    "    df = df.dropna()  # 删除空数据\n",
    "\n",
    "    # 归一化到0到1\n",
    "    X = np.vstack(df['Image'].values) / 255.  \n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    # 针对训练集目标标签进行归一化\n",
    "    if not test: \n",
    "        y = df[df.columns[:-1]].values\n",
    "        y = (y - 48) / 48  \n",
    "        X, y = shuffle(X, y, random_state=42)\n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将单行像素数据转换为三维矩阵\n",
    "def load2d(test=False, cols=None):\n",
    "    X, y = load(test=test, cols=cols)\n",
    "    X = X.reshape(-1, 1, 96, 96)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理\n",
    "\n",
    "一种方式是我们训练一个分类器，用来分类所有的目标特征。另一种是针对眼镜、鼻子、嘴分别设置不同的分类器，每个分类器只预测单个目标。通过观察数据我们发现，训练集中有许多缺失数据，如果训练一个分类器，删掉缺失数据会让我们的样本集变小，不能很好地利用起数据，因此，我们选择第二种方式，每个目标训练一个分类器，这样更好的利用样本数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from sklearn.base import clone\n",
    "\n",
    "SPECIALIST_SETTINGS = [\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eye_center_x', 'left_eye_center_y',\n",
    "            'right_eye_center_x', 'right_eye_center_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3)),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'nose_tip_x', 'nose_tip_y',\n",
    "            ),\n",
    "        flip_indices=(),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'mouth_left_corner_x', 'mouth_left_corner_y',\n",
    "            'mouth_right_corner_x', 'mouth_right_corner_y',\n",
    "            'mouth_center_top_lip_x', 'mouth_center_top_lip_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3)),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'mouth_center_bottom_lip_x',\n",
    "            'mouth_center_bottom_lip_y',\n",
    "            ),\n",
    "        flip_indices=(),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eye_inner_corner_x', 'left_eye_inner_corner_y',\n",
    "            'right_eye_inner_corner_x', 'right_eye_inner_corner_y',\n",
    "            'left_eye_outer_corner_x', 'left_eye_outer_corner_y',\n",
    "            'right_eye_outer_corner_x', 'right_eye_outer_corner_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3), (4, 6), (5, 7)),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eyebrow_inner_end_x', 'left_eyebrow_inner_end_y',\n",
    "            'right_eyebrow_inner_end_x', 'right_eyebrow_inner_end_y',\n",
    "            'left_eyebrow_outer_end_x', 'left_eyebrow_outer_end_y',\n",
    "            'right_eyebrow_outer_end_x', 'right_eyebrow_outer_end_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3), (4, 6), (5, 7)),\n",
    "        ),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FlipBatchIterator(BatchIterator):\n",
    "    flip_indices = [\n",
    "        (0, 2), (1, 3),\n",
    "        (4, 8), (5, 9), (6, 10), (7, 11),\n",
    "        (12, 16), (13, 17), (14, 18), (15, 19),\n",
    "        (22, 24), (23, 25),\n",
    "        ]\n",
    "\n",
    "    def transform(self, Xb, yb):\n",
    "        Xb, yb = super(FlipBatchIterator, self).transform(Xb, yb)\n",
    "\n",
    "        # Flip half of the images in this batch at random:\n",
    "        bs = Xb.shape[0]\n",
    "        indices = np.random.choice(bs, bs / 2, replace=False)\n",
    "        Xb[indices] = Xb[indices, :, :, ::-1]\n",
    "\n",
    "        if yb is not None:\n",
    "            # Horizontal flip of all x coordinates:\n",
    "            yb[indices, ::2] = yb[indices, ::2] * -1\n",
    "\n",
    "            # Swap places, e.g. left_eye_center_x -> right_eye_center_x\n",
    "            for a, b in self.flip_indices:\n",
    "                yb[indices, a], yb[indices, b] = (\n",
    "                    yb[indices, b], yb[indices, a])\n",
    "\n",
    "        return Xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EarlyStopping(object):\n",
    "    def __init__(self, patience=100):\n",
    "        self.patience = patience\n",
    "        self.best_valid = np.inf\n",
    "        self.best_valid_epoch = 0\n",
    "        self.best_weights = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        current_valid = train_history[-1]['valid_loss']\n",
    "        current_epoch = train_history[-1]['epoch']\n",
    "        if current_valid < self.best_valid:\n",
    "            self.best_valid = current_valid\n",
    "            self.best_valid_epoch = current_epoch\n",
    "            self.best_weights = nn.get_all_params_values()\n",
    "        elif self.best_valid_epoch + self.patience < current_epoch:\n",
    "            print(\"Early stopping.\")\n",
    "            print(\"Best valid loss was {:.6f} at epoch {}.\".format(\n",
    "                self.best_valid, self.best_valid_epoch))\n",
    "            nn.load_params_from(self.best_weights)\n",
    "            raise StopIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdjustVariable(object):\n",
    "    def __init__(self, name, start=0.03, stop=0.001):\n",
    "        self.name = name\n",
    "        self.start, self.stop = start, stop\n",
    "        self.ls = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.ls is None:\n",
    "            self.ls = np.linspace(self.start, self.stop, nn.max_epochs)\n",
    "\n",
    "        epoch = train_history[-1]['epoch']\n",
    "        new_value = np.cast['float32'](self.ls[epoch - 1])\n",
    "        getattr(nn, self.name).set_value(new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def float32(k):\n",
    "    return np.cast['float32'](k)\n",
    "\n",
    "net = NeuralNet(\n",
    "    layers=[\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv1', layers.Conv2DLayer),\n",
    "        ('pool1', layers.MaxPool2DLayer),\n",
    "        ('dropout1', layers.DropoutLayer),\n",
    "        ('conv2', layers.Conv2DLayer),\n",
    "        ('pool2', layers.MaxPool2DLayer),\n",
    "        ('dropout2', layers.DropoutLayer),\n",
    "        ('conv3', layers.Conv2DLayer),\n",
    "        ('pool3', layers.MaxPool2DLayer),\n",
    "        ('dropout3', layers.DropoutLayer),\n",
    "        ('hidden4', layers.DenseLayer),\n",
    "        ('dropout4', layers.DropoutLayer),\n",
    "        ('hidden5', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    input_shape=(None, 1, 96, 96),\n",
    "    conv1_num_filters=32, conv1_filter_size=(3, 3), pool1_pool_size=(2, 2),\n",
    "    dropout1_p=0.1,\n",
    "    conv2_num_filters=64, conv2_filter_size=(2, 2), pool2_pool_size=(2, 2),\n",
    "    dropout2_p=0.2,\n",
    "    conv3_num_filters=128, conv3_filter_size=(2, 2), pool3_pool_size=(2, 2),\n",
    "    dropout3_p=0.3,\n",
    "    hidden4_num_units=300,\n",
    "    dropout4_p=0.5,\n",
    "    hidden5_num_units=300,\n",
    "    output_num_units=30, output_nonlinearity=None,\n",
    "\n",
    "    update_learning_rate=theano.shared(float32(0.03)),\n",
    "    update_momentum=theano.shared(float32(0.9)),\n",
    "\n",
    "    regression=True,\n",
    "    batch_iterator_train = BatchIterator(batch_size = 100),\n",
    "    batch_iterator_test = BatchIterator(batch_size = 100),\n",
    "#     batch_iterator_train=FlipBatchIterator(batch_size=128),\n",
    "#     on_epoch_finished=[\n",
    "#         AdjustVariable('update_learning_rate', start=0.03, stop=0.0001),\n",
    "#         AdjustVariable('update_momentum', start=0.9, stop=0.999),\n",
    "#         EarlyStopping(patience=200),\n",
    "#         ],\n",
    "    max_epochs=10,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_specialists(fname_pretrain=None):\n",
    "    if fname_pretrain:\n",
    "        with open(fname_pretrain, 'rb') as f:\n",
    "            net_pretrain = pickle.load(f)\n",
    "    else:\n",
    "        net_pretrain = None\n",
    "\n",
    "    specialists = OrderedDict()\n",
    "\n",
    "    for setting in SPECIALIST_SETTINGS:\n",
    "        cols = setting['columns']\n",
    "        X, y = load2d(cols=cols)\n",
    "\n",
    "        model = clone(net)\n",
    "        model.output_num_units = y.shape[1]\n",
    "        model.batch_iterator_train.flip_indices = setting['flip_indices']\n",
    "        model.max_epochs = int(4e6 / y.shape[0])\n",
    "        if 'kwargs' in setting:\n",
    "            # an option 'kwargs' in the settings list may be used to\n",
    "            # set any other parameter of the net:\n",
    "            vars(model).update(setting['kwargs'])\n",
    "\n",
    "        if net_pretrain is not None:\n",
    "            # if a pretrain model was given, use it to initialize the\n",
    "            # weights of our new specialist model:\n",
    "            model.load_params_from(net_pretrain)\n",
    "\n",
    "        print(\"Training model for columns {} for {} epochs\".format(\n",
    "            cols, model.max_epochs))\n",
    "        model.fit(X, y)\n",
    "        specialists[cols] = model\n",
    "\n",
    "    with open('net-specialists.pickle', 'wb') as f:\n",
    "        # this time we're persisting a dictionary with all models:\n",
    "        pickle.dump(specialists, f, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(fname_specialists='net-specialists.pickle'):\n",
    "    with open(fname_specialists, 'rb') as f:\n",
    "        specialists = pickle.load(f)\n",
    "\n",
    "    X = load2d(test=True)[0]\n",
    "    y_pred = np.empty((X.shape[0], 0))\n",
    "\n",
    "    for model in specialists.values():\n",
    "        y_pred1 = model.predict(X)\n",
    "        y_pred = np.hstack([y_pred, y_pred1])\n",
    "\n",
    "    columns = ()\n",
    "    for cols in specialists.keys():\n",
    "        columns += cols\n",
    "\n",
    "    y_pred2 = y_pred * 48 + 48\n",
    "    y_pred2 = y_pred2.clip(0, 96)\n",
    "    df = DataFrame(y_pred2, columns=columns)\n",
    "\n",
    "    lookup_table = read_csv(os.path.expanduser(FLOOKUP))\n",
    "    values = []\n",
    "\n",
    "    for index, row in lookup_table.iterrows():\n",
    "        values.append((\n",
    "            row['RowId'],\n",
    "            df.ix[row.ImageId - 1][row.FeatureName],\n",
    "            ))\n",
    "\n",
    "    now_str = datetime.now().isoformat().replace(':', '-')\n",
    "    submission = DataFrame(values, columns=('RowId', 'Location'))\n",
    "    filename = 'submission-{}.csv'.format(now_str)\n",
    "    submission.to_csv(filename, index=False)\n",
    "    print(\"Wrote {}\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_eye_center_x     7039\n",
      "left_eye_center_y     7039\n",
      "right_eye_center_x    7036\n",
      "right_eye_center_y    7036\n",
      "Image                 7049\n",
      "dtype: int64\n",
      "Training model for columns ('left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x', 'right_eye_center_y') for 568 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/lasagne/layers/conv.py:489: UserWarning: The `image_shape` keyword argument to `tensor.nnet.conv2d` is deprecated, it has been renamed to `input_shape`.\n",
      "  border_mode=border_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 4779676 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  --------  ---------\n",
      "  0  input     1x96x96\n",
      "  1  conv1     32x94x94\n",
      "  2  pool1     32x47x47\n",
      "  3  dropout1  32x47x47\n",
      "  4  conv2     64x46x46\n",
      "  5  pool2     64x23x23\n",
      "  6  dropout2  64x23x23\n",
      "  7  conv3     128x22x22\n",
      "  8  pool3     128x11x11\n",
      "  9  dropout3  128x11x11\n",
      " 10  hidden4   300\n",
      " 11  dropout4  300\n",
      " 12  hidden5   300\n",
      " 13  output    4\n",
      "\n",
      "# Neural Network with 4779676 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  --------  ---------\n",
      "  0  input     1x96x96\n",
      "  1  conv1     32x94x94\n",
      "  2  pool1     32x47x47\n",
      "  3  dropout1  32x47x47\n",
      "  4  conv2     64x46x46\n",
      "  5  pool2     64x23x23\n",
      "  6  dropout2  64x23x23\n",
      "  7  conv3     128x22x22\n",
      "  8  pool3     128x11x11\n",
      "  9  dropout3  128x11x11\n",
      " 10  hidden4   300\n",
      " 11  dropout4  300\n",
      " 12  hidden5   300\n",
      " 13  output    4\n",
      "\n",
      "  epoch    trn loss    val loss    trn/val  dur\n",
      "-------  ----------  ----------  ---------  -------\n",
      "      1     \u001b[36m0.01113\u001b[0m     \u001b[32m0.00475\u001b[0m    2.34387  181.86s\n",
      "  epoch    trn loss    val loss    trn/val  dur\n",
      "-------  ----------  ----------  ---------  -------\n",
      "      1     \u001b[36m0.01113\u001b[0m     \u001b[32m0.00475\u001b[0m    2.34387  181.86s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    fit_specialists()\n",
    "    predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Warning\n",
    "\n",
    "单机执行实在是太慢了，这里可以使用Amazon AWS的GPU实例来运行程序，创建过程如下参见：[deep-learning-tutorial](https://www.kaggle.com/c/facial-keypoints-detection/details/deep-learning-tutorial)\n",
    "\n",
    "在运行实例之后还有几点要做：\n",
    "1. 安装python pip > sudo apt-get install python-pip python-dev build-essential   \n",
    "2. 创建Kaggle cookies文件，为了下载训练和测试数据，我们需要将本地浏览器中的cookies导出，通过chrome 插件：[https://chrome.google.com/webstore/detail/cookietxt-export/lopabhfecdfhgogdbojmaicoicjekelh/related](https://chrome.google.com/webstore/detail/cookietxt-export/lopabhfecdfhgogdbojmaicoicjekelh/related)   \n",
    "3. 把Github中的[https://github.com/wendykan/AWSGPU_DeepLearning](https://github.com/wendykan/AWSGPU_DeepLearning) clone到你的AWS实例中，进行一些机器学习的初始化工作。  \n",
    "\n",
    "一些参考：  \n",
    "http://ramhiser.com/2016/01/05/installing-tensorflow-on-an-aws-ec2-instance-with-gpu-support/\n",
    "http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
