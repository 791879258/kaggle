{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Red Hat Business Value\n",
    "\n",
    "数据存放在两个文件中，一个是关于人的信息，另外一个是关于活动的信息。people file包含了人、活动时间、活动的特征信息，每个人都有一个唯一的id，每一行刻画了一个人的相关信息。activity file包含了所有的活动信息。每一行代表一个人在何时进行了怎样的活动，每个活动有一个唯一的活动id。\n",
    "\n",
    "任务是预测人从事特定活动后的潜在商业价值，商业价值在活动文件中定义为yes/no[0或者1]，outcome列记录了一个人从事某个活动之后是否在特定时间窗口下达成了商业价值。\n",
    "\n",
    "活动文件有多种类型的活动，其中Type 1和Type 2~7有所不同，因为Type 1有更多的刻画特征特征（9个）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From：https://www.kaggle.com/abriosi/predicting-red-hat-business-value/raddar-0-98-xgboost-sparse-matrix-python\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 载入数据\n",
    "act_train_data = pd.read_csv(\"act_train.csv\",dtype={'people_id': np.str, 'activity_id': np.str, 'outcome': np.int8}, parse_dates=['date'])\n",
    "act_test_data  = pd.read_csv(\"act_test.csv\", dtype={'people_id': np.str, 'activity_id': np.str}, parse_dates=['date'])\n",
    "people_data    = pd.read_csv(\"people.csv\", dtype={'people_id': np.str, 'activity_id': np.str, 'char_38': np.int32}, parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  people_id   activity_id       date activity_category char_1 char_2 char_3  \\\n",
      "0   ppl_100  act2_1734928 2023-08-26            type 4    NaN    NaN    NaN   \n",
      "1   ppl_100  act2_2434093 2022-09-27            type 2    NaN    NaN    NaN   \n",
      "2   ppl_100  act2_3404049 2022-09-27            type 2    NaN    NaN    NaN   \n",
      "3   ppl_100  act2_3651215 2023-08-04            type 2    NaN    NaN    NaN   \n",
      "4   ppl_100  act2_4109017 2023-08-26            type 2    NaN    NaN    NaN   \n",
      "\n",
      "  char_4 char_5 char_6 char_7 char_8 char_9  char_10  outcome  \n",
      "0    NaN    NaN    NaN    NaN    NaN    NaN  type 76        0  \n",
      "1    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  \n",
      "2    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  \n",
      "3    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  \n",
      "4    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  \n",
      "    people_id   activity_id       date activity_category   char_1   char_2  \\\n",
      "0  ppl_100004   act1_249281 2022-07-20            type 1   type 5  type 10   \n",
      "1  ppl_100004   act2_230855 2022-07-20            type 5      NaN      NaN   \n",
      "2   ppl_10001   act1_240724 2022-10-14            type 1  type 12   type 1   \n",
      "3   ppl_10001    act1_83552 2022-11-27            type 1  type 20  type 10   \n",
      "4   ppl_10001  act2_1043301 2022-10-15            type 5      NaN      NaN   \n",
      "\n",
      "   char_3  char_4  char_5  char_6  char_7   char_8   char_9    char_10  \n",
      "0  type 5  type 1  type 6  type 1  type 1   type 7   type 4        NaN  \n",
      "1     NaN     NaN     NaN     NaN     NaN      NaN      NaN   type 682  \n",
      "2  type 5  type 4  type 6  type 1  type 1  type 13  type 10        NaN  \n",
      "3  type 5  type 4  type 6  type 1  type 1   type 5   type 5        NaN  \n",
      "4     NaN     NaN     NaN     NaN     NaN      NaN      NaN  type 3015  \n",
      "----------\n",
      "    people_id  char_1      group_1  char_2       date   char_3   char_4  \\\n",
      "0     ppl_100  type 2  group 17304  type 2 2021-06-29   type 5   type 5   \n",
      "1  ppl_100002  type 2   group 8688  type 3 2021-01-06  type 28   type 9   \n",
      "2  ppl_100003  type 2  group 33592  type 3 2022-06-10   type 4   type 8   \n",
      "3  ppl_100004  type 2  group 22593  type 3 2022-07-20  type 40  type 25   \n",
      "4  ppl_100006  type 2   group 6534  type 3 2022-07-27  type 40  type 25   \n",
      "\n",
      "   char_5  char_6   char_7   ...   char_29 char_30 char_31 char_32 char_33  \\\n",
      "0  type 5  type 3  type 11   ...     False    True    True   False   False   \n",
      "1  type 5  type 3  type 11   ...     False    True    True    True    True   \n",
      "2  type 5  type 2   type 5   ...     False   False    True    True    True   \n",
      "3  type 9  type 4  type 16   ...      True    True    True    True    True   \n",
      "4  type 9  type 3   type 8   ...     False   False    True   False   False   \n",
      "\n",
      "  char_34 char_35 char_36 char_37 char_38  \n",
      "0    True    True    True   False      36  \n",
      "1    True    True    True   False      76  \n",
      "2    True   False    True    True      99  \n",
      "3    True    True    True    True      76  \n",
      "4   False    True    True   False      84  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "print act_train_data.head()\n",
    "print act_test_data.head()\n",
    "print '----------\\n', people_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_dimen(dataset,column,toreplace):\n",
    "    for index,i in dataset[column].duplicated(keep=False).iteritems():\n",
    "        if i==False:\n",
    "            dataset.set_value(index,column,toreplace)\n",
    "    return dataset\n",
    "    \n",
    "def act_data_treatment(dsname):\n",
    "    dataset = dsname\n",
    "    \n",
    "    for col in list(dataset.columns):\n",
    "        if col not in ['people_id', 'activity_id', 'date', 'char_38', 'outcome']:\n",
    "            if dataset[col].dtype == 'object': # 将type 1解析为1\n",
    "                dataset[col].fillna('type 0', inplace=True)\n",
    "                dataset[col] = dataset[col].apply(lambda x: x.split(' ')[1]).astype(np.int32)\n",
    "            elif dataset[col].dtype == 'bool': # 对于布尔型数据，处理成0和1\n",
    "                dataset[col] = dataset[col].astype(np.int8)\n",
    "    \n",
    "    dataset['year'] = dataset['date'].dt.year\n",
    "    dataset['month'] = dataset['date'].dt.month\n",
    "    dataset['day'] = dataset['date'].dt.day\n",
    "    dataset['isweekend'] = (dataset['date'].dt.weekday >= 5).astype(int)\n",
    "    dataset = dataset.drop('date', axis = 1)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (2197291, 14)\n",
      "Test data shape: (498687, 13)\n",
      "People data shape: (189118, 41)\n",
      "  people_id   activity_id  activity_category  char_1  char_2  char_3  char_4  \\\n",
      "0   ppl_100  act2_1734928                  4       0       0       0       0   \n",
      "1   ppl_100  act2_2434093                  2       0       0       0       0   \n",
      "2   ppl_100  act2_3404049                  2       0       0       0       0   \n",
      "3   ppl_100  act2_3651215                  2       0       0       0       0   \n",
      "4   ppl_100  act2_4109017                  2       0       0       0       0   \n",
      "\n",
      "   char_5  char_6  char_7  char_8  char_9  outcome  year  month  day  \\\n",
      "0       0       0       0       0       0        0  2023      8   26   \n",
      "1       0       0       0       0       0        0  2022      9   27   \n",
      "2       0       0       0       0       0        0  2022      9   27   \n",
      "3       0       0       0       0       0        0  2023      8    4   \n",
      "4       0       0       0       0       0        0  2023      8   26   \n",
      "\n",
      "   isweekend  \n",
      "0          1  \n",
      "1          0  \n",
      "2          0  \n",
      "3          0  \n",
      "4          1  \n",
      "    people_id   activity_id  activity_category  char_1  char_2  char_3  \\\n",
      "0  ppl_100004   act1_249281                  1       5      10       5   \n",
      "1  ppl_100004   act2_230855                  5       0       0       0   \n",
      "2   ppl_10001   act1_240724                  1      12       1       5   \n",
      "3   ppl_10001    act1_83552                  1      20      10       5   \n",
      "4   ppl_10001  act2_1043301                  5       0       0       0   \n",
      "\n",
      "   char_4  char_5  char_6  char_7  char_8  char_9  year  month  day  isweekend  \n",
      "0       1       6       1       1       7       4  2022      7   20          0  \n",
      "1       0       0       0       0       0       0  2022      7   20          0  \n",
      "2       4       6       1       1      13      10  2022     10   14          0  \n",
      "3       4       6       1       1       5       5  2022     11   27          1  \n",
      "4       0       0       0       0       0       0  2022     10   15          1  \n",
      "    people_id  char_1  group_1  char_2  char_3  char_4  char_5  char_6  \\\n",
      "0     ppl_100       2    17304       2       5       5       5       3   \n",
      "1  ppl_100002       2     8688       3      28       9       5       3   \n",
      "2  ppl_100003       2    33592       3       4       8       5       2   \n",
      "3  ppl_100004       2    22593       3      40      25       9       4   \n",
      "4  ppl_100006       2     6534       3      40      25       9       3   \n",
      "\n",
      "   char_7  char_8    ...      char_33  char_34  char_35  char_36  char_37  \\\n",
      "0      11       2    ...            0        1        1        1        0   \n",
      "1      11       2    ...            1        1        1        1        0   \n",
      "2       5       2    ...            1        1        0        1        1   \n",
      "3      16       2    ...            1        1        1        1        1   \n",
      "4       8       2    ...            0        0        1        1        0   \n",
      "\n",
      "   char_38  year  month  day  isweekend  \n",
      "0       36  2021      6   29          0  \n",
      "1       76  2021      1    6          0  \n",
      "2       99  2022      6   10          0  \n",
      "3       76  2022      7   20          0  \n",
      "4       84  2022      7   27          0  \n",
      "\n",
      "[5 rows x 44 columns]\n",
      "after join:\n",
      "  people_id   activity_id  activity_category  char_1_x  char_2_x  char_3_x  \\\n",
      "0   ppl_100  act2_1734928                  4         0         0         0   \n",
      "0   ppl_100  act2_2434093                  2         0         0         0   \n",
      "0   ppl_100  act2_3404049                  2         0         0         0   \n",
      "0   ppl_100  act2_3651215                  2         0         0         0   \n",
      "0   ppl_100  act2_4109017                  2         0         0         0   \n",
      "\n",
      "   char_4_x  char_5_x  char_6_x  char_7_x     ...       char_33  char_34  \\\n",
      "0         0         0         0         0     ...             0        1   \n",
      "0         0         0         0         0     ...             0        1   \n",
      "0         0         0         0         0     ...             0        1   \n",
      "0         0         0         0         0     ...             0        1   \n",
      "0         0         0         0         0     ...             0        1   \n",
      "\n",
      "   char_35  char_36  char_37  char_38  year_y  month_y  day_y  isweekend_y  \n",
      "0        1        1        0       36    2021        6     29            0  \n",
      "0        1        1        0       36    2021        6     29            0  \n",
      "0        1        1        0       36    2021        6     29            0  \n",
      "0        1        1        0       36    2021        6     29            0  \n",
      "0        1        1        0       36    2021        6     29            0  \n",
      "\n",
      "[5 rows x 60 columns]\n",
      "test...\n",
      "    people_id   activity_id  activity_category  char_1_x  char_2_x  char_3_x  \\\n",
      "3  ppl_100004   act1_249281                  1         5        10         5   \n",
      "3  ppl_100004   act2_230855                  5         0         0         0   \n",
      "5   ppl_10001   act1_240724                  1        12         1         5   \n",
      "5   ppl_10001    act1_83552                  1        20        10         5   \n",
      "5   ppl_10001  act2_1043301                  5         0         0         0   \n",
      "\n",
      "   char_4_x  char_5_x  char_6_x  char_7_x     ...       char_33  char_34  \\\n",
      "3         1         6         1         1     ...             1        1   \n",
      "3         0         0         0         0     ...             1        1   \n",
      "5         4         6         1         1     ...             1        1   \n",
      "5         4         6         1         1     ...             1        1   \n",
      "5         0         0         0         0     ...             1        1   \n",
      "\n",
      "   char_35  char_36  char_37  char_38  year_y  month_y  day_y  isweekend_y  \n",
      "3        1        1        1       76    2022        7     20            0  \n",
      "3        1        1        1       76    2022        7     20            0  \n",
      "5        1        1        1       90    2022       10     14            0  \n",
      "5        1        1        1       90    2022       10     14            0  \n",
      "5        1        1        1       90    2022       10     14            0  \n",
      "\n",
      "[5 rows x 59 columns]\n"
     ]
    }
   ],
   "source": [
    "act_train_data=act_train_data.drop('char_10',axis=1)\n",
    "act_test_data=act_test_data.drop('char_10',axis=1)\n",
    "\n",
    "print(\"Train data shape: \" + format(act_train_data.shape))\n",
    "print(\"Test data shape: \" + format(act_test_data.shape))\n",
    "print(\"People data shape: \" + format(people_data.shape))\n",
    "\n",
    "# 预处理数据\n",
    "act_train_data  = act_data_treatment(act_train_data)\n",
    "act_test_data   = act_data_treatment(act_test_data)\n",
    "people_data = act_data_treatment(people_data)\n",
    "\n",
    "print act_train_data.head()\n",
    "print act_test_data.head()\n",
    "print people_data.head()\n",
    "\n",
    "# join到一起\n",
    "train = act_train_data.merge(people_data, on='people_id', how='left', left_index=True)\n",
    "test  = act_test_data.merge(people_data, on='people_id', how='left', left_index=True)\n",
    "\n",
    "print 'after join:'\n",
    "print train.head()\n",
    "print 'test...\\n', test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['people_id' 'activity_id' 'activity_category' 'char_1_x' 'char_2_x'\n",
      " 'char_3_x' 'char_4_x' 'char_5_x' 'char_6_x' 'char_7_x' 'char_8_x'\n",
      " 'char_9_x' 'outcome' 'year_x' 'month_x' 'day_x' 'isweekend_x' 'char_1_y'\n",
      " 'group_1' 'char_2_y' 'char_3_y' 'char_4_y' 'char_5_y' 'char_6_y'\n",
      " 'char_7_y' 'char_8_y' 'char_9_y' 'char_10' 'char_11' 'char_12' 'char_13'\n",
      " 'char_14' 'char_15' 'char_16' 'char_17' 'char_18' 'char_19' 'char_20'\n",
      " 'char_21' 'char_22' 'char_23' 'char_24' 'char_25' 'char_26' 'char_27'\n",
      " 'char_28' 'char_29' 'char_30' 'char_31' 'char_32' 'char_33' 'char_34'\n",
      " 'char_35' 'char_36' 'char_37' 'char_38' 'year_y' 'month_y' 'day_y'\n",
      " 'isweekend_y'] 60\n",
      "['people_id' 'activity_id' 'activity_category' 'char_1_x' 'char_2_x'\n",
      " 'char_3_x' 'char_4_x' 'char_5_x' 'char_6_x' 'char_7_x' 'char_8_x'\n",
      " 'char_9_x' 'year_x' 'month_x' 'day_x' 'isweekend_x' 'char_1_y' 'group_1'\n",
      " 'char_2_y' 'char_3_y' 'char_4_y' 'char_5_y' 'char_6_y' 'char_7_y'\n",
      " 'char_8_y' 'char_9_y' 'char_10' 'char_11' 'char_12' 'char_13' 'char_14'\n",
      " 'char_15' 'char_16' 'char_17' 'char_18' 'char_19' 'char_20' 'char_21'\n",
      " 'char_22' 'char_23' 'char_24' 'char_25' 'char_26' 'char_27' 'char_28'\n",
      " 'char_29' 'char_30' 'char_31' 'char_32' 'char_33' 'char_34' 'char_35'\n",
      " 'char_36' 'char_37' 'char_38' 'year_y' 'month_y' 'day_y' 'isweekend_y'] 59\n",
      "['year_x', 'char_3_y', 'char_10', 'people_id', 'char_33', 'char_2_y', 'group_1', 'activity_category', 'char_38', 'char_1_y', 'char_8_y', 'char_19', 'char_18', 'char_17', 'char_8_x', 'char_15', 'char_14', 'char_9_y', 'char_9_x', 'char_11', 'char_1_x', 'char_26', 'activity_id', 'char_3_x', 'isweekend_x', 'char_6_y', 'year_y', 'char_5_y', 'char_31', 'char_25', 'char_12', 'char_30', 'char_2_x', 'char_35', 'char_16', 'isweekend_y', 'char_27', 'char_24', 'char_32', 'char_22', 'char_23', 'char_20', 'char_5_x', 'char_4_x', 'char_13', 'char_21', 'char_28', 'char_29', 'day_x', 'day_y', 'char_37', 'char_6_x', 'char_4_y', 'char_34', 'char_36', 'month_x', 'month_y', 'char_7_y', 'char_7_x'] 59\n"
     ]
    }
   ],
   "source": [
    "train=train.sort_values(['people_id'], ascending=[1])\n",
    "test=test.sort_values(['people_id'], ascending=[1])\n",
    "\n",
    "train_columns = train.columns.values\n",
    "test_columns = test.columns.values\n",
    "features = list(set(train_columns) & set(test_columns)) # 求交集\n",
    "\n",
    "print train_columns, len(train_columns)\n",
    "print test_columns, len(test_columns)\n",
    "print features, len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.fillna('NA', inplace=True)\n",
    "test.fillna('NA', inplace=True)\n",
    "\n",
    "y = train.outcome\n",
    "train=train.drop('outcome',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  people_id   activity_id  activity_category  char_1_x  char_2_x  char_3_x  \\\n",
      "0   ppl_100  act2_1734928                  4         0         0         0   \n",
      "1   ppl_100  act2_2434093                  2         0         0         0   \n",
      "2   ppl_100  act2_3404049                  2         0         0         0   \n",
      "3   ppl_100  act2_3651215                  2         0         0         0   \n",
      "4   ppl_100  act2_4109017                  2         0         0         0   \n",
      "\n",
      "   char_4_x  char_5_x  char_6_x  char_7_x     ...       char_33  char_34  \\\n",
      "0         0         0         0         0     ...             0        1   \n",
      "1         0         0         0         0     ...             0        1   \n",
      "2         0         0         0         0     ...             0        1   \n",
      "3         0         0         0         0     ...             0        1   \n",
      "4         0         0         0         0     ...             0        1   \n",
      "\n",
      "   char_35  char_36  char_37  char_38  year_y  month_y  day_y  isweekend_y  \n",
      "0        1        1        0       36    2021        6     29            0  \n",
      "1        1        1        0       36    2021        6     29            0  \n",
      "2        1        1        0       36    2021        6     29            0  \n",
      "3        1        1        0       36    2021        6     29            0  \n",
      "4        1        1        0       36    2021        6     29            0  \n",
      "\n",
      "[5 rows x 59 columns]\n"
     ]
    }
   ],
   "source": [
    "whole = pd.concat([train,test],ignore_index=True)\n",
    "print whole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical=['group_1','activity_category','char_1_x','char_2_x','char_3_x','char_4_x','char_5_x','char_6_x','char_7_x','char_8_x','char_9_x','char_2_y','char_3_y','char_4_y','char_5_y','char_6_y','char_7_y','char_8_y','char_9_y']\n",
    "for category in categorical:\n",
    "    whole=reduce_dimen(whole,category,9999999)\n",
    "    \n",
    "X = whole[:len(train)]\n",
    "X_test = whole[len(train):]\n",
    "\n",
    "del train\n",
    "del whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.sort_values(['people_id'], ascending=[1])\n",
    "\n",
    "X = X[features].drop(['people_id', 'activity_id'], axis = 1)\n",
    "X_test = X_test[features].drop(['people_id', 'activity_id'], axis = 1)\n",
    "\n",
    "categorical=['group_1','activity_category','char_1_x','char_2_x','char_3_x','char_4_x','char_5_x','char_6_x','char_7_x','char_8_x','char_9_x','char_2_y','char_3_y','char_4_y','char_5_y','char_6_y','char_7_y','char_8_y','char_9_y']\n",
    "not_categorical=[]\n",
    "for category in X.columns:\n",
    "    if category not in categorical:\n",
    "        not_categorical.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X[not_categorical]\n",
      "(2197291, 38)\n",
      "(2197291, 31233)\n",
      "X_cat_sparse\n",
      "  (0, 31225)\t1.0\n",
      "  (0, 31217)\t1.0\n",
      "  (0, 31201)\t1.0\n",
      "  (0, 31186)\t1.0\n",
      "  (0, 31179)\t1.0\n",
      "  (0, 31154)\t1.0\n",
      "  (0, 31111)\t1.0\n",
      "  (0, 31105)\t1.0\n",
      "  (0, 31084)\t1.0\n",
      "  (0, 31065)\t1.0\n",
      "  (0, 31056)\t1.0\n",
      "  (0, 31050)\t1.0\n",
      "  (0, 31042)\t1.0\n",
      "  (0, 31034)\t1.0\n",
      "  (0, 31022)\t1.0\n",
      "  (0, 30989)\t1.0\n",
      "  (0, 30937)\t1.0\n",
      "  (0, 30933)\t1.0\n",
      "  (0, 10990)\t1.0\n",
      "  (1, 31225)\t1.0\n",
      "  (1, 31217)\t1.0\n",
      "  (1, 31201)\t1.0\n",
      "  (1, 31186)\t1.0\n",
      "  (1, 31179)\t1.0\n",
      "  (1, 31154)\t1.0\n",
      "  :\t:\n",
      "  (2197289, 31034)\t1.0\n",
      "  (2197289, 31022)\t1.0\n",
      "  (2197289, 30989)\t1.0\n",
      "  (2197289, 30937)\t1.0\n",
      "  (2197289, 30931)\t1.0\n",
      "  (2197289, 11348)\t1.0\n",
      "  (2197290, 31225)\t1.0\n",
      "  (2197290, 31217)\t1.0\n",
      "  (2197290, 31192)\t1.0\n",
      "  (2197290, 31184)\t1.0\n",
      "  (2197290, 31176)\t1.0\n",
      "  (2197290, 31156)\t1.0\n",
      "  (2197290, 31108)\t1.0\n",
      "  (2197290, 31106)\t1.0\n",
      "  (2197290, 31084)\t1.0\n",
      "  (2197290, 31065)\t1.0\n",
      "  (2197290, 31056)\t1.0\n",
      "  (2197290, 31050)\t1.0\n",
      "  (2197290, 31042)\t1.0\n",
      "  (2197290, 31034)\t1.0\n",
      "  (2197290, 31022)\t1.0\n",
      "  (2197290, 30989)\t1.0\n",
      "  (2197290, 30937)\t1.0\n",
      "  (2197290, 30931)\t1.0\n",
      "  (2197290, 11348)\t1.0\n",
      "X_test_cat_sparse\n",
      "  (0, 31225)\t1.0\n",
      "  (0, 31217)\t1.0\n",
      "  (0, 31206)\t1.0\n",
      "  (0, 31187)\t1.0\n",
      "  (0, 31183)\t1.0\n",
      "  (0, 31174)\t1.0\n",
      "  (0, 31146)\t1.0\n",
      "  (0, 31106)\t1.0\n",
      "  (0, 31088)\t1.0\n",
      "  (0, 31072)\t1.0\n",
      "  (0, 31057)\t1.0\n",
      "  (0, 31051)\t1.0\n",
      "  (0, 31048)\t1.0\n",
      "  (0, 31035)\t1.0\n",
      "  (0, 31027)\t1.0\n",
      "  (0, 30999)\t1.0\n",
      "  (0, 30942)\t1.0\n",
      "  (0, 30930)\t1.0\n",
      "  (0, 14834)\t1.0\n",
      "  (1, 31225)\t1.0\n",
      "  (1, 31217)\t1.0\n",
      "  (1, 31206)\t1.0\n",
      "  (1, 31187)\t1.0\n",
      "  (1, 31183)\t1.0\n",
      "  (1, 31174)\t1.0\n",
      "  :\t:\n",
      "  (498685, 31034)\t1.0\n",
      "  (498685, 31022)\t1.0\n",
      "  (498685, 30989)\t1.0\n",
      "  (498685, 30937)\t1.0\n",
      "  (498685, 30931)\t1.0\n",
      "  (498685, 10990)\t1.0\n",
      "  (498686, 31229)\t1.0\n",
      "  (498686, 31221)\t1.0\n",
      "  (498686, 31198)\t1.0\n",
      "  (498686, 31186)\t1.0\n",
      "  (498686, 31183)\t1.0\n",
      "  (498686, 31174)\t1.0\n",
      "  (498686, 31146)\t1.0\n",
      "  (498686, 31105)\t1.0\n",
      "  (498686, 31084)\t1.0\n",
      "  (498686, 31065)\t1.0\n",
      "  (498686, 31056)\t1.0\n",
      "  (498686, 31050)\t1.0\n",
      "  (498686, 31042)\t1.0\n",
      "  (498686, 31034)\t1.0\n",
      "  (498686, 31022)\t1.0\n",
      "  (498686, 30989)\t1.0\n",
      "  (498686, 30937)\t1.0\n",
      "  (498686, 30931)\t1.0\n",
      "  (498686, 10990)\t1.0\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc = enc.fit(pd.concat([X[categorical],X_test[categorical]]))\n",
    "X_cat_sparse = enc.transform(X[categorical])\n",
    "X_test_cat_sparse = enc.transform(X_test[categorical])\n",
    "print 'X[not_categorical]'\n",
    "print X[not_categorical].shape\n",
    "print X_cat_sparse.shape\n",
    "print 'X_cat_sparse'\n",
    "print X_cat_sparse\n",
    "print 'X_test_cat_sparse'\n",
    "print X_test_cat_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "X_sparse=hstack((X[not_categorical], X_cat_sparse))\n",
    "X_test_sparse=hstack((X_test[not_categorical], X_test_cat_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X[not_categorical]\n",
      "(2197291, 38)\n",
      "(2197291, 31233)\n",
      "(2197291, 31271)\n",
      "X_cat_sparse\n",
      "  (0, 31225)\t1.0\n",
      "  (0, 31217)\t1.0\n",
      "  (0, 31201)\t1.0\n",
      "  (0, 31186)\t1.0\n",
      "  (0, 31179)\t1.0\n",
      "  (0, 31154)\t1.0\n",
      "  (0, 31111)\t1.0\n",
      "  (0, 31105)\t1.0\n",
      "  (0, 31084)\t1.0\n",
      "  (0, 31065)\t1.0\n",
      "  (0, 31056)\t1.0\n",
      "  (0, 31050)\t1.0\n",
      "  (0, 31042)\t1.0\n",
      "  (0, 31034)\t1.0\n",
      "  (0, 31022)\t1.0\n",
      "  (0, 30989)\t1.0\n",
      "  (0, 30937)\t1.0\n",
      "  (0, 30933)\t1.0\n",
      "  (0, 10990)\t1.0\n",
      "  (1, 31225)\t1.0\n",
      "  (1, 31217)\t1.0\n",
      "  (1, 31201)\t1.0\n",
      "  (1, 31186)\t1.0\n",
      "  (1, 31179)\t1.0\n",
      "  (1, 31154)\t1.0\n",
      "  :\t:\n",
      "  (2197289, 31034)\t1.0\n",
      "  (2197289, 31022)\t1.0\n",
      "  (2197289, 30989)\t1.0\n",
      "  (2197289, 30937)\t1.0\n",
      "  (2197289, 30931)\t1.0\n",
      "  (2197289, 11348)\t1.0\n",
      "  (2197290, 31225)\t1.0\n",
      "  (2197290, 31217)\t1.0\n",
      "  (2197290, 31192)\t1.0\n",
      "  (2197290, 31184)\t1.0\n",
      "  (2197290, 31176)\t1.0\n",
      "  (2197290, 31156)\t1.0\n",
      "  (2197290, 31108)\t1.0\n",
      "  (2197290, 31106)\t1.0\n",
      "  (2197290, 31084)\t1.0\n",
      "  (2197290, 31065)\t1.0\n",
      "  (2197290, 31056)\t1.0\n",
      "  (2197290, 31050)\t1.0\n",
      "  (2197290, 31042)\t1.0\n",
      "  (2197290, 31034)\t1.0\n",
      "  (2197290, 31022)\t1.0\n",
      "  (2197290, 30989)\t1.0\n",
      "  (2197290, 30937)\t1.0\n",
      "  (2197290, 30931)\t1.0\n",
      "  (2197290, 11348)\t1.0\n",
      "  (0, 0)\t2023.0\n",
      "  (0, 1)\t1.0\n",
      "  (0, 3)\t36.0\n",
      "  (0, 4)\t2.0\n",
      "  (0, 9)\t1.0\n",
      "  (0, 12)\t1.0\n",
      "  (0, 13)\t2021.0\n",
      "  (0, 14)\t1.0\n",
      "  (0, 17)\t1.0\n",
      "  (0, 18)\t1.0\n",
      "  (0, 19)\t1.0\n",
      "  (0, 21)\t1.0\n",
      "  (0, 27)\t1.0\n",
      "  (0, 28)\t1.0\n",
      "  (0, 29)\t1.0\n",
      "  (0, 31)\t26.0\n",
      "  (0, 32)\t29.0\n",
      "  (0, 34)\t1.0\n",
      "  (0, 35)\t1.0\n",
      "  (0, 36)\t8.0\n",
      "  (0, 37)\t6.0\n",
      "  (1, 0)\t2022.0\n",
      "  (1, 1)\t1.0\n",
      "  (1, 3)\t36.0\n",
      "  (1, 4)\t2.0\n",
      "  :\t:\n",
      "  (2197289, 31072)\t1.0\n",
      "  (2197289, 31060)\t1.0\n",
      "  (2197289, 31027)\t1.0\n",
      "  (2197289, 30975)\t1.0\n",
      "  (2197289, 30969)\t1.0\n",
      "  (2197289, 11386)\t1.0\n",
      "  (2197290, 31263)\t1.0\n",
      "  (2197290, 31255)\t1.0\n",
      "  (2197290, 31230)\t1.0\n",
      "  (2197290, 31222)\t1.0\n",
      "  (2197290, 31214)\t1.0\n",
      "  (2197290, 31194)\t1.0\n",
      "  (2197290, 31146)\t1.0\n",
      "  (2197290, 31144)\t1.0\n",
      "  (2197290, 31122)\t1.0\n",
      "  (2197290, 31103)\t1.0\n",
      "  (2197290, 31094)\t1.0\n",
      "  (2197290, 31088)\t1.0\n",
      "  (2197290, 31080)\t1.0\n",
      "  (2197290, 31072)\t1.0\n",
      "  (2197290, 31060)\t1.0\n",
      "  (2197290, 31027)\t1.0\n",
      "  (2197290, 30975)\t1.0\n",
      "  (2197290, 30969)\t1.0\n",
      "  (2197290, 11386)\t1.0\n",
      "X_test_cat_sparse\n",
      "  (0, 31225)\t1.0\n",
      "  (0, 31217)\t1.0\n",
      "  (0, 31206)\t1.0\n",
      "  (0, 31187)\t1.0\n",
      "  (0, 31183)\t1.0\n",
      "  (0, 31174)\t1.0\n",
      "  (0, 31146)\t1.0\n",
      "  (0, 31106)\t1.0\n",
      "  (0, 31088)\t1.0\n",
      "  (0, 31072)\t1.0\n",
      "  (0, 31057)\t1.0\n",
      "  (0, 31051)\t1.0\n",
      "  (0, 31048)\t1.0\n",
      "  (0, 31035)\t1.0\n",
      "  (0, 31027)\t1.0\n",
      "  (0, 30999)\t1.0\n",
      "  (0, 30942)\t1.0\n",
      "  (0, 30930)\t1.0\n",
      "  (0, 14834)\t1.0\n",
      "  (1, 31225)\t1.0\n",
      "  (1, 31217)\t1.0\n",
      "  (1, 31206)\t1.0\n",
      "  (1, 31187)\t1.0\n",
      "  (1, 31183)\t1.0\n",
      "  (1, 31174)\t1.0\n",
      "  :\t:\n",
      "  (498685, 31034)\t1.0\n",
      "  (498685, 31022)\t1.0\n",
      "  (498685, 30989)\t1.0\n",
      "  (498685, 30937)\t1.0\n",
      "  (498685, 30931)\t1.0\n",
      "  (498685, 10990)\t1.0\n",
      "  (498686, 31229)\t1.0\n",
      "  (498686, 31221)\t1.0\n",
      "  (498686, 31198)\t1.0\n",
      "  (498686, 31186)\t1.0\n",
      "  (498686, 31183)\t1.0\n",
      "  (498686, 31174)\t1.0\n",
      "  (498686, 31146)\t1.0\n",
      "  (498686, 31105)\t1.0\n",
      "  (498686, 31084)\t1.0\n",
      "  (498686, 31065)\t1.0\n",
      "  (498686, 31056)\t1.0\n",
      "  (498686, 31050)\t1.0\n",
      "  (498686, 31042)\t1.0\n",
      "  (498686, 31034)\t1.0\n",
      "  (498686, 31022)\t1.0\n",
      "  (498686, 30989)\t1.0\n",
      "  (498686, 30937)\t1.0\n",
      "  (498686, 30931)\t1.0\n",
      "  (498686, 10990)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print 'X[not_categorical]'\n",
    "print X[not_categorical].shape\n",
    "print X_cat_sparse.shape\n",
    "print X_sparse.shape\n",
    "print 'X_cat_sparse'\n",
    "print X_cat_sparse\n",
    "print X_sparse\n",
    "print 'X_test_cat_sparse'\n",
    "print X_test_cat_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Training data: \" + format(X_sparse.shape))\n",
    "print(\"Test data: \" + format(X_test_sparse.shape))\n",
    "print(\"###########\")\n",
    "print(\"One Hot enconded Test Dataset Script\")\n",
    "\n",
    "dtrain = xgb.DMatrix(X_sparse,label=y)\n",
    "dtest = xgb.DMatrix(X_test_sparse)\n",
    "\n",
    "param = {'max_depth':10, 'eta':0.02, 'silent':1, 'objective':'binary:logistic' }\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "param['subsample'] = 0.7\n",
    "param['colsample_bytree']= 0.7\n",
    "param['min_child_weight'] = 0\n",
    "param['booster'] = \"gblinear\"\n",
    "\n",
    "watchlist  = [(dtrain,'train')]\n",
    "num_round = 300\n",
    "early_stopping_rounds=10\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist,early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "ypred = bst.predict(dtest)\n",
    "output = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred })\n",
    "output.head()\n",
    "output.to_csv('without_leak.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
