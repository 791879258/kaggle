{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据概览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 载入数据\n",
    "train = pd.read_csv('/Users/frank/Documents/workspace/kaggle/dataset/San_Francisco_Crime_Classification/train.csv', parse_dates = ['Dates'])\n",
    "test = pd.read_csv('/Users/frank/Documents/workspace/kaggle/dataset/San_Francisco_Crime_Classification/test.csv', parse_dates = ['Dates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预览训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Dates        Category                        Descript  \\\n",
      "0 2015-05-13 23:53:00        WARRANTS                  WARRANT ARREST   \n",
      "1 2015-05-13 23:53:00  OTHER OFFENSES        TRAFFIC VIOLATION ARREST   \n",
      "2 2015-05-13 23:33:00  OTHER OFFENSES        TRAFFIC VIOLATION ARREST   \n",
      "3 2015-05-13 23:30:00   LARCENY/THEFT    GRAND THEFT FROM LOCKED AUTO   \n",
      "4 2015-05-13 23:30:00   LARCENY/THEFT    GRAND THEFT FROM LOCKED AUTO   \n",
      "5 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM UNLOCKED AUTO   \n",
      "6 2015-05-13 23:30:00   VEHICLE THEFT               STOLEN AUTOMOBILE   \n",
      "7 2015-05-13 23:30:00   VEHICLE THEFT               STOLEN AUTOMOBILE   \n",
      "8 2015-05-13 23:00:00   LARCENY/THEFT    GRAND THEFT FROM LOCKED AUTO   \n",
      "9 2015-05-13 23:00:00   LARCENY/THEFT    GRAND THEFT FROM LOCKED AUTO   \n",
      "\n",
      "   DayOfWeek PdDistrict      Resolution                        Address  \\\n",
      "0  Wednesday   NORTHERN  ARREST, BOOKED             OAK ST / LAGUNA ST   \n",
      "1  Wednesday   NORTHERN  ARREST, BOOKED             OAK ST / LAGUNA ST   \n",
      "2  Wednesday   NORTHERN  ARREST, BOOKED      VANNESS AV / GREENWICH ST   \n",
      "3  Wednesday   NORTHERN            NONE       1500 Block of LOMBARD ST   \n",
      "4  Wednesday       PARK            NONE      100 Block of BRODERICK ST   \n",
      "5  Wednesday  INGLESIDE            NONE            0 Block of TEDDY AV   \n",
      "6  Wednesday  INGLESIDE            NONE            AVALON AV / PERU AV   \n",
      "7  Wednesday    BAYVIEW            NONE       KIRKWOOD AV / DONAHUE ST   \n",
      "8  Wednesday   RICHMOND            NONE           600 Block of 47TH AV   \n",
      "9  Wednesday    CENTRAL            NONE  JEFFERSON ST / LEAVENWORTH ST   \n",
      "\n",
      "            X          Y  \n",
      "0 -122.425892  37.774599  \n",
      "1 -122.425892  37.774599  \n",
      "2 -122.424363  37.800414  \n",
      "3 -122.426995  37.800873  \n",
      "4 -122.438738  37.771541  \n",
      "5 -122.403252  37.713431  \n",
      "6 -122.423327  37.725138  \n",
      "7 -122.371274  37.727564  \n",
      "8 -122.508194  37.776601  \n",
      "9 -122.419088  37.807802  \n"
     ]
    }
   ],
   "source": [
    "print train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预览测试集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id               Dates DayOfWeek PdDistrict                   Address  \\\n",
      "0   0 2015-05-10 23:59:00    Sunday    BAYVIEW   2000 Block of THOMAS AV   \n",
      "1   1 2015-05-10 23:51:00    Sunday    BAYVIEW        3RD ST / REVERE AV   \n",
      "2   2 2015-05-10 23:50:00    Sunday   NORTHERN    2000 Block of GOUGH ST   \n",
      "3   3 2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
      "4   4 2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
      "5   5 2015-05-10 23:40:00    Sunday    TARAVAL     BROAD ST / CAPITOL AV   \n",
      "6   6 2015-05-10 23:30:00    Sunday  INGLESIDE   100 Block of CHENERY ST   \n",
      "7   7 2015-05-10 23:30:00    Sunday  INGLESIDE     200 Block of BANKS ST   \n",
      "8   8 2015-05-10 23:10:00    Sunday    MISSION     2900 Block of 16TH ST   \n",
      "9   9 2015-05-10 23:10:00    Sunday    CENTRAL      TAYLOR ST / GREEN ST   \n",
      "\n",
      "            X          Y  \n",
      "0 -122.399588  37.735051  \n",
      "1 -122.391523  37.732432  \n",
      "2 -122.426002  37.792212  \n",
      "3 -122.437394  37.721412  \n",
      "4 -122.437394  37.721412  \n",
      "5 -122.459024  37.713172  \n",
      "6 -122.425616  37.739351  \n",
      "7 -122.412652  37.739750  \n",
      "8 -122.418700  37.765165  \n",
      "9 -122.413935  37.798886  \n"
     ]
    }
   ],
   "source": [
    "print test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看到训练集和测试集都有Dates、DayOfWeek、PdDistrict三个特征，我们先从这三个特征入手。训练集中的Category是我们的预测目标，我们先对其进行编码，这里用到sklearn的LabelEncoder()，示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "label = preprocessing.LabelEncoder()\n",
    "label.fit([1, 2, 2, 6])\n",
    "print label.transform([1, 1, 2, 6]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们对类别进行编码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crime = label.fit_transform(train.Category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于离散化的特征，有一种常用的特征处理方式是二值化处理，pandas中有get_dummies()函数，函数示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c\n",
       "0  1.0  0.0  0.0\n",
       "1  0.0  1.0  0.0\n",
       "2  0.0  0.0  1.0\n",
       "3  1.0  0.0  0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(pd.Series(list('abca')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来对Dates、DayOfWeek、PdDistrict三个特征进行二值化处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "days = pd.get_dummies(train.DayOfWeek)\n",
    "district = pd.get_dummies(train.PdDistrict)\n",
    "hour = pd.get_dummies(train.Dates.dt.hour) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来重新组合训练集，并把类别附加上："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.concat([days, district, hour], axis=1)\n",
    "train_data['crime'] = crime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对测试集做同样的处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "days = pd.get_dummies(test.DayOfWeek)\n",
    "district = pd.get_dummies(test.PdDistrict)\n",
    "hour = pd.get_dummies(test.Dates.dt.hour) \n",
    "test_data = pd.concat([days, district, hour], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预览新的训练集和测试集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Friday  Monday  Saturday  Sunday  Thursday  Tuesday  Wednesday  BAYVIEW  \\\n",
      "0     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   \n",
      "1     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   \n",
      "2     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   \n",
      "3     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   \n",
      "4     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   \n",
      "5     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   \n",
      "6     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   \n",
      "7     0.0     0.0       0.0     0.0       0.0      0.0        1.0      1.0   \n",
      "8     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   \n",
      "9     0.0     0.0       0.0     0.0       0.0      0.0        1.0      0.0   \n",
      "\n",
      "   CENTRAL  INGLESIDE  ...     15   16   17   18   19   20   21   22   23  \\\n",
      "0      0.0        0.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "1      0.0        0.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "2      0.0        0.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "3      0.0        0.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "4      0.0        0.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "5      0.0        1.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "6      0.0        1.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "7      0.0        0.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "8      0.0        0.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "9      1.0        0.0  ...    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "\n",
      "   crime  \n",
      "0     37  \n",
      "1     21  \n",
      "2     21  \n",
      "3     16  \n",
      "4     16  \n",
      "5     16  \n",
      "6     36  \n",
      "7     36  \n",
      "8     16  \n",
      "9     16  \n",
      "\n",
      "[10 rows x 42 columns]\n",
      "   Friday  Monday  Saturday  Sunday  Thursday  Tuesday  Wednesday  BAYVIEW  \\\n",
      "0     0.0     0.0       0.0     1.0       0.0      0.0        0.0      1.0   \n",
      "1     0.0     0.0       0.0     1.0       0.0      0.0        0.0      1.0   \n",
      "2     0.0     0.0       0.0     1.0       0.0      0.0        0.0      0.0   \n",
      "3     0.0     0.0       0.0     1.0       0.0      0.0        0.0      0.0   \n",
      "4     0.0     0.0       0.0     1.0       0.0      0.0        0.0      0.0   \n",
      "5     0.0     0.0       0.0     1.0       0.0      0.0        0.0      0.0   \n",
      "6     0.0     0.0       0.0     1.0       0.0      0.0        0.0      0.0   \n",
      "7     0.0     0.0       0.0     1.0       0.0      0.0        0.0      0.0   \n",
      "8     0.0     0.0       0.0     1.0       0.0      0.0        0.0      0.0   \n",
      "9     0.0     0.0       0.0     1.0       0.0      0.0        0.0      0.0   \n",
      "\n",
      "   CENTRAL  INGLESIDE ...    14   15   16   17   18   19   20   21   22   23  \n",
      "0      0.0        0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "1      0.0        0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "2      0.0        0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "3      0.0        1.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "4      0.0        1.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "5      0.0        0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "6      0.0        1.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "7      0.0        1.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "8      0.0        0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "9      1.0        0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "\n",
      "[10 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "print train_data.head(10)\n",
    "print test_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分割训练集和验证集(70%训练,30%验证)准备建模："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "training, validation = train_test_split(train_data, train_size=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 贝叶斯训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选取的特征列： ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "朴素贝叶斯log损失为 2.581561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "model = BernoulliNB()\n",
    "feature_list = training.columns.tolist()\n",
    "feature_list = feature_list[:len(feature_list) - 1]\n",
    "print '选取的特征列：', feature_list\n",
    "model.fit(training[feature_list], training['crime'])\n",
    "\n",
    "predicted = np.array(model.predict_proba(validation[feature_list]))\n",
    "print \"朴素贝叶斯log损失为 %f\" % (log_loss(validation['crime'], predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "逻辑回归log损失为 2.580102\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(C=0.1)\n",
    "model.fit(training[feature_list], training['crime'])\n",
    "\n",
    "predicted = np.array(model.predict_proba(validation[feature_list]))\n",
    "print \"逻辑回归log损失为 %f\" %(log_loss(validation['crime'], predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在测试集上运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predicted = np.array(model.predict_proba(test_data[feature_list]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARSON' 'ASSAULT' 'BAD CHECKS' 'BRIBERY' 'BURGLARY' 'DISORDERLY CONDUCT'\n",
      " 'DRIVING UNDER THE INFLUENCE' 'DRUG/NARCOTIC' 'DRUNKENNESS' 'EMBEZZLEMENT'\n",
      " 'EXTORTION' 'FAMILY OFFENSES' 'FORGERY/COUNTERFEITING' 'FRAUD' 'GAMBLING'\n",
      " 'KIDNAPPING' 'LARCENY/THEFT' 'LIQUOR LAWS' 'LOITERING' 'MISSING PERSON'\n",
      " 'NON-CRIMINAL' 'OTHER OFFENSES' 'PORNOGRAPHY/OBSCENE MAT' 'PROSTITUTION'\n",
      " 'RECOVERED VEHICLE' 'ROBBERY' 'RUNAWAY' 'SECONDARY CODES'\n",
      " 'SEX OFFENSES FORCIBLE' 'SEX OFFENSES NON FORCIBLE' 'STOLEN PROPERTY'\n",
      " 'SUICIDE' 'SUSPICIOUS OCC' 'TREA' 'TRESPASS' 'VANDALISM' 'VEHICLE THEFT'\n",
      " 'WARRANTS' 'WEAPON LAWS']\n"
     ]
    }
   ],
   "source": [
    "col_names = np.sort(train['Category'].unique())\n",
    "print col_names\n",
    "result = pd.DataFrame(data=test_predicted, columns=col_names)\n",
    "result['Id'] = test['Id'].astype(int)\n",
    "result.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
